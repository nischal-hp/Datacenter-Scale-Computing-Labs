USER=$(shell whoami)

##
## Changed the Makefile to make it work with the GCP dataproc enviornment
##

HADOOP_CLASSPATH=$(shell hadoop classpath)

WordCount1.jar: WordCount1.java
	javac -classpath $(HADOOP_CLASSPATH) -d ./ WordCount1.java
	jar cf WordCount1.jar WordCount1*.class	
	-rm -f WordCount1*.class

prepare:
	-hdfs dfs -mkdir input
	curl https://en.wikipedia.org/wiki/Apache_Hadoop > /tmp/input.txt
	hdfs dfs -put /tmp/input.txt input/file01
	curl https://en.wikipedia.org/wiki/MapReduce > /tmp/input.txt
	hdfs dfs -put /tmp/input.txt input/file02

filesystem:
	-hdfs dfs -mkdir /user
	-hdfs dfs -mkdir /user/$(USER)

run: WordCount1.jar
	-rm -rf output
	hadoop jar WordCount1.jar WordCount1 input output


##
## Changed the path to the STREAM_JAR and the first command under stream
## 
##
HADOOP_V=3.2.1
STREAM_JAR = /usr/lib/hadoop-mapreduce/hadoop-streaming.jar

stream:
	hadoop fs -rm -R hdfs://cluster-lab2-m/user/student-04-927014e902ae/stream-output
	hadoop jar $(STREAM_JAR) \
	-mapper URLMapper.py \
	-reducer URLReducer.py \
	-file URLMapper.py -file URLReducer.py \
	-input input -output stream-output
